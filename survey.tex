\documentclass[acmsmall, 12pt]{acmart}

\begin{document}

\title{A Survey of Medical Imaging Reconstructions and Rendering}
\author{Cameron Stevenson}
\affiliation{
 \institution{University of Canterbury}
 \streetaddress{Ilam}
 \city{Christchurch}
 \state{Canterbury}
 \country{New Zealand}}
 
\begin{abstract}
Abstract a b c
\end{abstract}

\maketitle

\section{Introduction}

Intro a b c

\section{Overview}

Overview a b c

\section{Image Processing}

\subsection{Segmentation}

Birkfellner \cite{birkfellner2016applied} observes that organs are usually composed of multiple tissue types, which show up as different intensities under imaging. This makes segmentation "a rather complex, specialized procedure often requiring considerable manual interaction". Particular organs are focussed on when developing segmentation methods.

Birkfellner \cite{birkfellner2016applied} covers some advanced segmentation methods. The watershed transform for example uses the physical idea of water running to the bottom of valleys in a landscape. After taking a gradient transform on an image, edges are peaks in the landscape, and the virtual water will fill up basins representing segments in the image. Various interpretations of the physical behaviour can be used.

Mukundan \cite{mukundan2016reconstruction} observes that in HRCT lung scans, tissue regions are "characterized by different and easily separable intensity levels". Simple thresholding can be used to pick out regions. 

\subsection{Contour Finding}

Mukundan \cite{mukundan2016reconstruction} starts with a binary image after thresholding. Eroding the image with a 3x3 element then subtracting this from the thresholded image gives one pixel wide edges. Sequential edge following is used to extract contours. Discarding small contours reduces the number of contours significantly.

Pu et al. \cite{pu2008adaptive} introduce a border marching algorithm with an adaptive step size to find the outer contours of the lungs. The metric for adjusting the step size for a border segment is based on how far (at most) the segment lies from the true border. This method has the advantage of including juxtapleural pulmonary modules in the segmentation despite their imaged intensity being dissimilar to the rest of the lung.

Mackay \cite{mackay2019robust} uses contours generated from Adaptive Contour Marching.

\subsection{Contour Interpolation}

Barrett et al. \cite{barrett1994image} present a contour interpolation algorithm in image space based on morphological operations. An image with both contours present (as different grayscale values) is dilated until the space between contours is filled. The front where the two dilations meet is where the interpolated contour is found. It is noted that this method handles branching cases with no modification necessary.

\section{Volumetric Rendering}

\section{Rasterization}

Splatting takes each voxel's value and "splats" it against the drawn image, contributing to a few pixels, with its contribution fading away as you move outwards.

Texture-based volume rendering intersects many planes with the volume \cite{ohiotexture}. On these planes polygons are rendered, with mappings from their coordinates to the 3D space of the volume, to get texture values. 

\subsection{Raycasting}

Maximum intensity projection (MIP) is a raycasting method where rays project the most intense voxel they pass through \cite{birkfellner2016applied}. The images produced have high contrast detail and are easy to understand.

Summed voxel rendering is another raycasting method where rays sum up intensities from every voxel they pass through, giving a blurred image \cite{birkfellner2016applied}.

Intersecting arbitrary rays with voxels can be computationally expensive. Shear-warp rendering solves this by using projections which make rays orthogonal to the voxel axes \cite{lacroute1994fast}. 


\section{Surface Reconstructions}

\subsection{Marching Cubes}

Marching cubes \cite{lorensen1987marching} converts voxels into surfaces. Each voxel either belongs to a structure or does not, based on imaged intensity. Surface voxels ("inside" voxels bordering "outside" voxels) are found. Each voxel is assigned primitives based on which of their neighbours are inside or outside the structure, using a lookup table. The primitives are joined in neighbouring surface voxels to form the overall mesh. The results tend to look jagged and smoothing is usually applied either to the mesh or during rendering for a more visually appealing output.

\subsection{Point Cloud Methods}

\subsection{Finding Normals}

Mitra et al. \cite{mitra2003estimating} use least squares distance to fit a plane to a neighbourhood of points for each point in the cloud. There is a sweet spot for the radius of the neighbourhood used. Small radius makes noisy points have more impact on the plane found, and large radius allows for surface curvature to introduce error. 

\subsection{Contour Correspondence}
contour correspondence...

\subsection{Point Correspondence}
Point correspondence is an optional step in surface reconstructions, where points on matched contours are matched to each other as a precursor to triangulation.

Mackay \cite{mackay2019robust} proposes Dynamic Time Warping (DTW) as a method of point correspondence. DTW is intended to match features on the same structure across different times. In point correspondence, it matches points on contours which are from the same structure but in different slices, so slightly warped. 

\subsection{Mesh Triangulation}
mesh triangulation...

\subsection{The Branching Problem}

Mackay \cite{mackay2019robust} uses contour merging to help DTW point correspondence in the branching case. In a slice with one contour and a slice with two contours, the two contours are merged at their nearest point to give one larger contour. Point correspondence between the matched contours can then proceed as normal.

\subsection{Mesh Rendering}
mesh rendering...

\section{Testing}

\subsection{Measuring Similarity in Segmentation}

Pixel-wise XOR operations are common.

Pu et al. \cite{pu2008adaptive} use a reference segmentation (defined by experts) and evaluate their result by the distribution along the contour of distance error from this reference.

\subsection{Generating Models}

Mackay \cite{mackay2019robust} uses Blender3D to create test models, by creating surface of revolutions about bezier curves. 

Pluta et al. \cite{pluta2012new} propose a rule-based method of generating models, including deformations and noise.

\subsection{Measuring Similarity in 3D Models}

Mackay \cite{mackay2019robust} uses Hausdorff distance (essentially a maximum deviation between point sets) to measure mesh similarity. Points are sampled from a ground truth model and the nearest distance is found to the reconstructed model.

\section{Conclusion}

\bibliographystyle{acm}
\bibliography{references}

\end{document}