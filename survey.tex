\documentclass[acmsmall, 12pt]{acmart}

\begin{document}

\title{A Survey of Medical Imaging Reconstructions and Rendering}
\author{Cameron Stevenson}
\affiliation{
 \institution{University of Canterbury}
 \streetaddress{Ilam}
 \city{Christchurch}
 \state{Canterbury}
 \country{New Zealand}}
 
\begin{abstract}
Abstract a b c
\end{abstract}

\maketitle

\section{Introduction}

Intro a b c

\section{Overview}

Overview a b c

slices = sections

\section{Image Processing}

\subsection{Segmentation}

Birkfellner \cite{birkfellner2016applied} observes that organs are usually composed of multiple tissue types, which show up as different intensities under imaging. This makes segmentation "a rather complex, specialized procedure often requiring considerable manual interaction". Particular organs are focussed on when developing segmentation methods.

Birkfellner \cite{birkfellner2016applied} covers some advanced segmentation methods. The watershed transform for example uses the physical idea of water running to the bottom of valleys in a landscape. After taking a gradient transform on an image, edges are peaks in the landscape, and the virtual water will fill up basins representing segments in the image. Various interpretations of the physical behaviour can be used.

Mukundan \cite{mukundan2016reconstruction} observes that in HRCT lung scans, tissue regions are "characterized by different and easily separable intensity levels". Simple thresholding can be used to pick out regions. 

\subsection{Contour Finding}

Mukundan \cite{mukundan2016reconstruction} starts with a binary image after thresholding. Eroding the image with a 3x3 element then subtracting this from the thresholded image gives one pixel wide edges. Sequential edge following is used to extract contours. Discarding small contours reduces the number of contours significantly.

Pu et al. \cite{pu2008adaptive} introduce a border marching algorithm with an adaptive step size to find the outer contours of the lungs. The metric for adjusting the step size for a border segment is based on how far (at most) the segment lies from the true border. This method has the advantage of including juxtapleural pulmonary modules in the segmentation despite their imaged intensity being dissimilar to the rest of the lung.

Mackay \cite{mackay2019robust} uses contours generated from Adaptive Contour Marching.

\subsection{Contour Interpolation}

Barrett et al. \cite{barrett1994image} present a contour interpolation algorithm in image space based on morphological operations. An image with both contours present (as different grayscale values) is dilated until the space between contours is filled. The front where the two dilations meet is where the interpolated contour is found. It is noted that this method handles branching cases with no modification necessary.

\section{Volumetric Rendering}


\section{Rasterization}

Splatting takes each voxel's value and "splats" it against the drawn image, contributing to a few pixels, with its contribution fading away as you move outwards.

Texture-based volume rendering intersects many planes with the volume \cite{ohiotexture}. On these planes polygons are rendered, with mappings from their coordinates to the 3D space of the volume, to get texture values. 

\subsection{Raycasting}

Maximum intensity projection (MIP) is a raycasting method where rays project the most intense voxel they pass through \cite{birkfellner2016applied}. The images produced have high contrast detail and are easy to understand.

Summed voxel rendering is another raycasting method where rays sum up intensities from every voxel they pass through, giving a blurred image \cite{birkfellner2016applied}.

Intersecting arbitrary rays with voxels can be computationally expensive. Shear-warp rendering solves this by using projections which make rays orthogonal to the voxel axes \cite{lacroute1994fast}. 


Fishman et al. \cite{fishman2006volume} make comparisons between maximum intensity projection and other volume rendering. MIP tends to not contrast the background well with the structure of interest. Other volume rendering methods can weight voxels differently and give different tissue types different colours. 

\section{Surface Reconstructions}

\subsection{Marching Cubes}

Marching cubes \cite{lorensen1987marching} converts voxels into surfaces. Each voxel either belongs to a structure or does not, based on imaged intensity. Surface voxels ("inside" voxels bordering "outside" voxels) are found. Each voxel is assigned primitives based on which of their neighbours are inside or outside the structure, using a lookup table. The primitives are joined in neighbouring surface voxels to form the overall mesh. The results tend to look jagged and smoothing is usually applied either to the mesh or during rendering for a more visually appealing output.

\subsection{Point Cloud Methods}

Approximate - don't have to go through points
Inteporlate - have to go through points

It is common to define a function from 3D space to a value so that the surface is found where the function output is zero, then an isosurface is generated.

Braude et al. \cite{braude2007contour} employ Multi-level Partition of Unity (MPU) implicit models to generate isosurfaces from. MPU closely approximates Euclidean distance near points. This method requires surface normals. 

Guennebaud et al. \cite{guennebaud2007algebraic} fit algebraic spheres to point sets to construct surfaces. Their method (APSS) performs better than prior methods on sharp features and sparse data.

Oztireli et al. \cite{oztireli2009feature} combine Moving Least Squares (MLS) with local kernel regression to obtain Robust Implicit Moving Least Squares (RIMLS). This method reconstructs sharp (non-smooth) corners more accurately than APSS.

Taubin et al. \cite{taubin2012smooth} demonstrate colour maps extrapolated from source points onto a reconstructed surface.

\subsection{Estimating Normals}

Mitra et al. \cite{mitra2003estimating} use least squares distance to fit a plane to a neighbourhood of points for each point in the cloud. There is a sweet spot for the radius of the neighbourhood used. Small radius makes noisy points have more impact on the plane found, and large radius allows for surface curvature to introduce error. 

\subsection{Contour Correspondence}
contour correspondence...

Herbert et al. \cite{herbert2001contour} classify correspondence algorithms into four types.
\begin{itemize}
\item Manual methods use user input to connect contours. This is time consuming for large datasets.
\item Local algorithms takes pairs of slices at a time and considers contour matchings between these.
\item Global algorithms look for contour pairings across all sections.
\item Growing algorithms create a hierarchy of components, attempting to join unmatched contours onto existing components if suitable.
\end{itemize}


Herbert et al. \cite{herbert2001contour} suggest growing objects one contour at a time instead of considering pairings of contours globally. In preprocessing spacial information is gathered such as contour characteristics (position, shape, size), intra-sectional relationships between contours (to validate complex structures later), and inter-sectional relationships. Contour relationship metrics include distance between centroids, distance between major/minor axes, minimum bounding rectangle overlap, shape comparison via compactness ratios, and surroundness (how deep is the contour nested in larger contours).

Herbert et al. \cite{herbert2001contour} include semantic information given by the user on the expected components in a reconstruction, and their spatial relation to each other. A starting contour is found for each component before the growing process starts.

\subsection{Point Correspondence}
Point correspondence is an optional step in surface reconstructions, where points on matched contours are matched to each other as a precursor to triangulation.

Mackay \cite{mackay2019robust} proposes Dynamic Time Warping (DTW) as a method of point correspondence. DTW is intended to match features on the same structure across different times. In point correspondence, it matches points on contours which are from the same structure but in different slices, so slightly warped. 

\subsection{Mesh Triangulation}

Mackay \cite{mackay2019robust} begins with two ordered sets of points X and Y, from the two contours matched, with some edges provided by point correspondence. As a result of the constraints on DTW, there are three cases for each point $x_{m}$ on the first contour:
\begin{itemize}
\item $x_{m}$ has an edge with $y_{n}$ and $x_{m+1}$ has an edge with $y_{n+1}$. These points are direct neighbours on their respective contours, and form a quad which is trivial to triangulate.
\item $x_{m}$ has edges with a sequence of points $\{y_{n}, y_{n+1}, ..., y{n+i}\}$. $x_{m}$ has a one-to-many point correspondence with these points. This can be triangulated with a triangle fan centreing about $x_{m}$.
\item Each point in the sequence $\{x_{m}, x_{m+1}, ..., x{m+i}\}$ has edges with a point $y_{n}$. This is the opposite of the previous case and can likewise be triangulated with a triangle fan centreing about $y_{n}$.

\end{itemize}

\subsection{The Branching Problem}

Mackay \cite{mackay2019robust} uses contour merging to help DTW point correspondence in the branching case. In a contour correspondence where there is a slice with a single contour and a slice with two contours, the two contours on the same slice are merged at their nearest point to give one larger contour. Point correspondence between the single contour and the merged contour can then proceed as normal.

\subsection{Mesh Rendering}
mesh rendering...

\section{Testing}

\subsection{Measuring Similarity in Segmentation}

Pixel-wise XOR operations are common.

Pu et al. \cite{pu2008adaptive} use a reference segmentation (defined by experts) and evaluate their result by the distribution along the contour of distance error from this reference.

\subsection{Generating Models}

Mackay \cite{mackay2019robust} uses Blender3D to create test models, by creating surface of revolutions about bezier curves. 

Pluta et al. \cite{pluta2012new} propose a rule-based method of generating models, including deformations and noise.

\subsection{Measuring Similarity in 3D Models}

Mackay \cite{mackay2019robust} uses Hausdorff distance (essentially a maximum deviation between point sets) to measure mesh similarity. Points are sampled from a ground truth model and the nearest distance is found to the reconstructed model.

\section{Conclusion}

\bibliographystyle{acm}
\bibliography{references}

\end{document}